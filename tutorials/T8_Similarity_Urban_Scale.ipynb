{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/AiDAPT-A/2024-Q3-ai-in-architecture/blob/main/tutorials/T8_Similarity_Urban_Scale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv6AHLeeMU2h"
      },
      "source": [
        "\n",
        "# Building similarity at the urban scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPG3Su1SCirr"
      },
      "source": [
        "## üìå Overview\n",
        "By following this tutorial, you will learn how to conduct urban data-driven analysis at scale by computing *combined building similarity scores*.\n",
        "More specifically, you will automatically extract both aerial and street view imagery from building footprints and corresponding geographical information. Then, you will integrate meaningful building image features computed via pre-trained computer vision foundation models. Finally, you will be able to visualize and interpret urban similarity maps.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1pWpCu7CwTzQIygkq5hHw0nLZDZLcz2Td\" alt=\"floor-layout\" class=\"center\" width=\"1000px\">\n",
        "</center>\n",
        "\n",
        "### üß† **Learning objectives**\n",
        "- Visualize and interpret *urban* representations at scale\n",
        "- Create a customized dataset of aerial and **street view** images\n",
        "- Generate an urban similarity score by combining similarity scores computed from both aerial and street view images\n",
        "\n",
        "### üêç **New in Python**\n",
        "- (Reminder) HTTP requests: `requests`\n",
        "- (Tips) Coordinate reference system operations: `pyproj`\n",
        "\n",
        "### üåç 1. Building footprint\n",
        "- **Geopandas and 3D BAG**: Recall what you learned in Tutorial 4 (from building footprints to photos).\n",
        "\n",
        "### üì∏ 2. Aerial and street view images\n",
        "- **Boundary definition and image extraction**: Recall what you learned in Tutorials 4 and 5 (from photos to embeddings).\n",
        "\n",
        "### üë• 3. Building similarity\n",
        "- **Similarity measures**: Recall what you learned in Tutorial 5.\n",
        "- **Urban similarity visualization**: Interpret and visualize building similarity at scale on a map.\n",
        "\n",
        "### üíª Group assignment\n",
        "- **Practical exercise**: Apply what you have learned and create your own urban similarity map."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOi8GHRyN66b"
      },
      "source": [
        "## üè¢ Building footprints: GeoPandas (3D BAG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r97RwKvZdlTN"
      },
      "source": [
        "You very well know how to manage directories at this point. Am I right?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC-8dlV_Lwsd"
      },
      "outputs": [],
      "source": [
        "# import drive and os libraries\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# mount google drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# set a directory of your choice\n",
        "working_path = \"/content/drive/MyDrive/voorhof_class\"\n",
        "# chdir to change the directory\n",
        "os.chdir(working_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hHGdbfjdplg"
      },
      "source": [
        "Let's start from the tile of building footprints collected in [Tutorial 4](https://colab.research.google.com/drive/1Ja8qsEVmx7tgDciPcKnqiOsPaPYZ3hft?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaaxS2DwOGjK"
      },
      "outputs": [],
      "source": [
        "import geopandas\n",
        "## Load GeoPandas file\n",
        "path_to_data = \"filtered_buildings.gpkg\" # This should contain the name of the downloaded geopandas file\n",
        "filtered_buildings = geopandas.read_file(path_to_data)\n",
        "filtered_buildings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJAmhfUDehRT"
      },
      "outputs": [],
      "source": [
        "subset_buildings = filtered_buildings.iloc[0:50]  # The same 50 buildings\n",
        "\n",
        "subset_buildings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsJ25Yjleh9w"
      },
      "source": [
        "Cross-check the file has been loaded correctly by plotting the tile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNM5KHkOOU0f"
      },
      "outputs": [],
      "source": [
        "# Plot buildings footprint\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "subset_buildings.plot(column='b3_dak_type', legend=True, alpha=0.8) # Footprint roof type\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upvsqAaVe5LY"
      },
      "source": [
        "### Processing geographical coordinates for each building\n",
        "\n",
        "This time, you will extract both street view images. Following the process described in Tutorial 4, let's first find out the geographical coordinates needed to automate the image extraction process.\n",
        "\n",
        "- **Street view images** can be retrieved via Cyclomedia's API based on a specified location in 2D geographical coordinates. The API will then send the closest street view image from the specified location. A possible choice is defining the building coordinate as the centroid of the rectangular bounding box. You can explore other options reported in the API's [documentation](https://developer.cyclomedia.com/our-apis/panorama-rendering-api/).\n",
        "\n",
        "- (Reminder) **Aerial images** can be extracted via PDOK by defining the two corners of a rectangular bounding box. If you need more details to complete this step, do you know where to look at? Sure, you know! Tutorial 4.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1VjAOuUjoiafMd-TMCazMIR1cndHfBMxK\" alt=\"floor-layout\" class=\"center\" width=\"500px\">\n",
        "</center>\n",
        "\n",
        "In this tutorial, we will take 50 buildings (the same buildings selected in Tutorials 4 and 5), and will determine the coordinates for extracting street view images.\n",
        "\n",
        "For bookkeeping purposes, you can append the coordinates in a dictionary and store them as json files: `build_dic_streetview.json`. \\\\\n",
        "‚ö† This will be really handy when you are working on your final project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q72lS8sgOgxM"
      },
      "outputs": [],
      "source": [
        "# Load Python modules\n",
        "import numpy as np\n",
        "import json\n",
        "from shapely.geometry import MultiPolygon\n",
        "'''\n",
        "get coordinates for each building and stored them in a dictionary\n",
        "    - Loop over BAG IDs\n",
        "    - Extract coordinates\n",
        "    - Compute bounding box\n",
        "    - Store results\n",
        "'''\n",
        "\n",
        "additional_padding = 10 # let's add some context (note that this variable is defined in meters)\n",
        "\n",
        "'''\n",
        "Create a dictionary build_coord where:\n",
        "- Key: building_index (ind_build) # Think of this like a building ID\n",
        "- Value: A list with a box coordinates\n",
        "\n",
        "'''\n",
        "build_coord = {}\n",
        "street_view_coord = {}\n",
        "\n",
        "for index, row in subset_buildings.iterrows():\n",
        "\n",
        "    # Let's only collect the ID\n",
        "    pand_id = row[\"identificatie\"][14:]\n",
        "\n",
        "    geometry = row.geometry  # Retrieve geometry (could be Polygon or MultiPolygon)\n",
        "    if isinstance(geometry, MultiPolygon):  # Check if it's a MultiPolygon\n",
        "        coords = [np.array(polygon.exterior.coords) for polygon in geometry.geoms]\n",
        "    else:  # It's a single Polygon\n",
        "        coords = [np.array(geometry.exterior.coords)]\n",
        "    # Flatten the list if you need a single set of coordinates\n",
        "    coord = np.vstack(coords)\n",
        "\n",
        "    # Dictionary: aerial images\n",
        "    coord_box = []\n",
        "    coord_box.append(coord[:,0].min() - additional_padding)\n",
        "    coord_box.append(coord[:,1].min() - additional_padding)\n",
        "    coord_box.append(coord[:,0].max() + additional_padding)\n",
        "    coord_box.append(coord[:,1].max() + additional_padding)\n",
        "\n",
        "    # Let's make sure the bounding box is a square\n",
        "    sides = np.array((coord_box[2] - coord_box[0], coord_box[3] - coord_box[1]))\n",
        "    index_max = np.argmax(sides)\n",
        "    index_min = np.argmin(sides)\n",
        "    increment = (sides[index_max]/2) - (sides[index_min]/2)\n",
        "    coord_box[index_min] = coord_box[index_min] - increment\n",
        "    coord_box[index_min+2] = coord_box[index_min+2] + increment\n",
        "\n",
        "    # Add a dictionary item\n",
        "    build_coord[pand_id] = coord_box\n",
        "\n",
        "    # Dictionary: street view images\n",
        "    coord_point = []\n",
        "    coord_point.append(coord[:,0].min() + (coord[:,0].max() - coord[:,0].min()) / 2)\n",
        "    coord_point.append(coord[:,1].min() + (coord[:,1].max() - coord[:,1].min()) / 2)\n",
        "    street_view_coord[pand_id] = coord_point\n",
        "\n",
        "# with open(\"build_dic_aerial.json\", 'w') as file_id:\n",
        "#     json.dump(build_coord, file_id)\n",
        "\n",
        "with open(\"build_dic_streetview.json\", 'w') as file_id:\n",
        "    json.dump(street_view_coord, file_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO6O9j6_hf5O"
      },
      "source": [
        "Shall we verify the generated/stored dictionary makes sense?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG7pGwz_P4Xt"
      },
      "outputs": [],
      "source": [
        "street_view_coord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIXu0c3KMii9"
      },
      "source": [
        "## üì∏ (Recap) Retrieving street view images via Cyclomedia's API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF9FHp5sh1oW"
      },
      "source": [
        "You already know how to use Cyclomedia's API. The focus here will hence be on automatically retrieving street view images.\n",
        "\n",
        "(Bookkeeping) Where we are at?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SUpB-NcRXT8"
      },
      "outputs": [],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l94U9zJifWG"
      },
      "source": [
        "Below, we will load the required Python module to launch URL requests and create a function to ask Cyclomedia's API the street view images you would like to extract."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioZygDWuRTDE"
      },
      "outputs": [],
      "source": [
        "# As usual in Python, let's load the necessary modules\n",
        "import requests\n",
        "from requests.auth import HTTPBasicAuth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUyTkzjIutv1"
      },
      "source": [
        "The get_image function allows you to automatically download a panoramic image from Cyclomedia's API by specifying a location and how you want to view it.\n",
        "\n",
        "What the function does:\n",
        "+ Takes input coordinates (COOR_X and COOR_Y) in a local coordinate system (CRS 28992).\n",
        "\n",
        "+ Constructs a URL to request a panorama image from Cyclomedia using those coordinates.\n",
        "\n",
        "+ Sends a request to the Cyclomedia server, asking for an image with specific view settings (like field of view, direction, and image size).\n",
        "\n",
        "+ Saves the image locally with a name you choose.\n",
        "\n",
        "+ Returns the image path if successful, or prints an error if something goes wrong.\n",
        "\n",
        "Important inputs you can adjust:\n",
        "+ `name_image`: what you want to call the image file.\n",
        "\n",
        "+ `path_image`: folder or location where you want to save the image.\n",
        "\n",
        "+ `hfov`: horizontal field of view (in degrees) ‚Äî wider values show more of the scene.\n",
        "\n",
        "+ `pitch`: up/down angle of the camera.\n",
        "\n",
        "+ `yaw`: left/right angle (direction you're looking).\n",
        "\n",
        "+ `width and height`: size of the image in pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJiVV3Q4RJFk"
      },
      "outputs": [],
      "source": [
        "def get_image(COOR_X,\n",
        "            COOR_Y,\n",
        "            name_image='image_0',\n",
        "            path_image='',\n",
        "            hfov='90',\n",
        "            pitch='0',\n",
        "            yaw='0',\n",
        "            width='1200',\n",
        "            height='1200',\n",
        "            index='0'):\n",
        "\n",
        "    # ! Specify you user and pass here (very private) :)\n",
        "    username = ' ' #Your user here\n",
        "    password = ' ' #Your pass here\n",
        "\n",
        "    # Construct the URL to connect with the API\n",
        "    URL_START = 'https://atlasapi.cyclomedia.com/api/PanoramaRendering/RenderByLocation2D/'\n",
        "    CRS = '28992'\n",
        "    API_KEY = '2XU9ajAxS3YtKvgVCD4h-30lK3IpOb8x-HApGTcRCf09a7UVuX8h-r4ZarYZ2nIB'\n",
        "    # COOR_X = '94313.15'\n",
        "    # COOR_Y = '435711.11'\n",
        "    HFOV = hfov\n",
        "    PITCH = pitch\n",
        "    YAW = yaw\n",
        "    WIDTH = width\n",
        "    HEIGHT = height\n",
        "    INDEX = index\n",
        "\n",
        "    file_name = path_image + name_image + '.jpg'\n",
        "\n",
        "    url = URL_START \\\n",
        "    + CRS + '/' \\\n",
        "    + COOR_X + '/' + COOR_Y \\\n",
        "    + '/?width=' + WIDTH + '&height=' + HEIGHT \\\n",
        "    + '&hfov=' + HFOV \\\n",
        "    + '&apiKey=' + API_KEY \\\n",
        "    + '&pitch=' + PITCH + '&yaw=' + YAW \\\n",
        "    + '&index=' + INDEX\n",
        "\n",
        "    # Contact the API and request the images\n",
        "    response = requests.get(url, auth=HTTPBasicAuth(username, password))\n",
        "\n",
        "    if response.status_code == 200: # This means everything went well\n",
        "        with open(file_name, 'wb') as f:\n",
        "            f.write(response.content) # Store the images\n",
        "        return file_name\n",
        "    else: # If there was an error, we need to know about it!\n",
        "        print('Error: ', response.status_code)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMGVlUsci54x"
      },
      "source": [
        "Where would you like to store all the street view images? Define the directory below. Note that the folder should exist in your GDrive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsXSHCAQRkhY"
      },
      "outputs": [],
      "source": [
        "#directory where the street view images will be stored\n",
        "street_view_images_path = \"/content/drive/MyDrive/voorhof_class/street_view_images/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BzfYS0rjIAT"
      },
      "source": [
        "Just a reminder: let's check how a single image can be retrieved and we will then automate the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q50duB0jSA6m"
      },
      "outputs": [],
      "source": [
        "# Only one image (easy!)\n",
        "# coor_x = '68554.7'\n",
        "# coor_y = '445294.4'\n",
        "# get_image(coor_x, coor_y, 'image_0', street_view_images_path, yaw='0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utVa5VvyjRYK"
      },
      "source": [
        "Well, you have work very hard up to this point. It is time for your PC (or should we say Collab?) to do the work for you by automating the process.\n",
        "\n",
        "Iterate over the geographical coordinates determined for each building footprint and request the corresponding street view image. Unless Cyclomedia already limited your quota, this should work! Enjoy seeing how street images are flowing to your local directory. üòé"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq6nV-wcMoXn"
      },
      "outputs": [],
      "source": [
        "for build_id, coord in street_view_coord.items():\n",
        "  get_image(str(coord[0]), str(coord[1]), str(build_id), street_view_images_path, yaw='0')\n",
        "  #print(build_id, coord)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWA27_kwMou5"
      },
      "source": [
        "## üíª Computing **urban** embeddings via DinoV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyNfLCu3kWY-"
      },
      "source": [
        "Being that we are ambitious, we will not stop at computing embeddings (meaningful representations) separetely for aerial and street view images, we will compute similarity scores for both!\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1hXzNURGqRK8Si30BJoDICV8RDtTOintb\" alt=\"floor-layout\" class=\"center\" width=\"400px\">\n",
        "</center>\n",
        "\n",
        "To speak Dino's language, transform the extracted images as shown below and stored the transformed street view images as a torch tensor.\n",
        "Let's also load the previously computed *aerial image* embeddings. Certainly, you are familiar with this process!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uEBCWpRjYtE"
      },
      "outputs": [],
      "source": [
        "# Get vector embeddings from a aerial images\n",
        "# Load modules\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMoaf0tLjdH5"
      },
      "outputs": [],
      "source": [
        "aerial_embed = torch.load('embeddings/vorhof_0_50.pt') # Load previously computed embeddings (from building aerial images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UiUu9xojsro"
      },
      "outputs": [],
      "source": [
        "print(aerial_embed.shape) # Shape... check!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SelEPEnMUiHO"
      },
      "outputs": [],
      "source": [
        "# This is the directory where the extracted images are stored:\n",
        "# street_view_images_path #\n",
        "\n",
        "# Specify here which transformations will be applied to the image\n",
        "transform = T.Compose([\n",
        "    T.Resize(224, interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "# Prepare a list with all images filenames to run everything in a loop fashion\n",
        "transformed_images = [] # Initialize a list for the transformed images\n",
        "list_build_images = [] # This list will contain the building ids\n",
        "\n",
        "# And here comes the loop iterating over all images\n",
        "for img_filename in os.listdir(street_view_images_path):\n",
        "    img_path = os.path.join(street_view_images_path, img_filename) # Combine path and image name\n",
        "    list_build_images.append(img_filename.split('.')[0]) # Append the building id to the list\n",
        "    print(img_path) # Let's print out the processed images\n",
        "\n",
        "    if os.path.isfile(img_path):\n",
        "        img = Image.open(img_path) # The image is opened by PIL Image function (Think of PIL as a translator)\n",
        "        t_img = transform(img) # The transformation is now applied here\n",
        "        transformed_images.append(t_img)  # Append the transformed image to the list\n",
        "\n",
        "# Convert list of tensors to a single 4D tensor (Recall: one image would be a 3D tensor)\n",
        "tensor_streetview_images = torch.stack(transformed_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VFU93gLkZAA"
      },
      "outputs": [],
      "source": [
        "# tensor_images is now a 4D tensor of shape [N, C, H, W], where N is the number of images\n",
        "print(tensor_streetview_images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isKBRVQHlZsc"
      },
      "source": [
        "Let's summon Dino up to our collab notebook and compute embeddings from our street view images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJQGPcNXUMXc"
      },
      "outputs": [],
      "source": [
        "dinov2_vits14_reg = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14_reg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeyHgNDSUdor"
      },
      "outputs": [],
      "source": [
        "# Let's compute embeddings from street view imagery\n",
        "with torch.no_grad():\n",
        "    streetview_embed = dinov2_vits14_reg(tensor_streetview_images)\n",
        "\n",
        "print(aerial_embed.shape, streetview_embed.shape) # Just to check the shape of the tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT0oI3ESXNw0"
      },
      "source": [
        "## üëÅ Urban similarity based on cosine similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjiY3ZmDnYPK"
      },
      "source": [
        "Great, you can now rely on the embeddings computed from both aerial and street-view images and perform a variety of tasks.\n",
        "\n",
        "In this tutorial, we will again focus on information retrieval and will determine (dis)similar buildings based on urban cosine similarity. To do so, we will combine the cosine similarity scores calculated for both aerial and street-view images. You can decide which importance weight should be assign to each of them.\n",
        "\n",
        "Reusing a function defined in Tutorial 5, we can compute the cosine similarity scores among all picked buildings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ChDfH9KXP-m"
      },
      "outputs": [],
      "source": [
        "# Define the function to compute cosine similarity scores\n",
        "def cosine_similarity(x):\n",
        "    num_samples = x.size(0) # Size of our tensor\n",
        "    similarity = torch.zeros((num_samples, num_samples)) # Initialize a tensor where the scores will be stored\n",
        "\n",
        "    # Looping over the elements in the tensor\n",
        "    # We will compute the similarity scores of all elements with all elements\n",
        "    for i in range(num_samples):\n",
        "        for j in range(num_samples):\n",
        "            # Compute the similarity score between x[i] and x[j]\n",
        "            similarity[i, j] = torch.dot(x[i], x[j]) / torch.norm(x[i], p=2) / torch.norm(x[j], p=2)\n",
        "\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_r89Hd_oGcn"
      },
      "source": [
        "In fact, let's calculate cosine similarity scores based on the embeddings computed for all cases: (i) aerial images, (ii) street view images, (iii) combined urban similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBD55Yd4XYj1"
      },
      "outputs": [],
      "source": [
        "similarity_aerial = cosine_similarity(aerial_embed)\n",
        "similarity_streetview = cosine_similarity(streetview_embed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWVAVAB1yzIC"
      },
      "source": [
        "We are combining two types of visual similarity to compute an overall urban similarity score:\n",
        "\n",
        "- `similarity_aerial`: measures how similar two locations are based on **aerial imagery** (top-down view).\n",
        "- `similarity_streetview`: measures similarity using **street-level images** (what you see at eye level).\n",
        "\n",
        "The weights define how much each view contributes to the final score:\n",
        "\n",
        "```python\n",
        "w_aerial = 0.5\n",
        "w_streetview = 0.5\n",
        "```\n",
        "In this example, both views are given equal importance. Feel free to adjust the weights when you calculate urban similarity scores for your final project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R6KhDDhlTak"
      },
      "outputs": [],
      "source": [
        "w_aerial = 0.5\n",
        "w_streetview = 0.5\n",
        "similarity_urban = w_aerial * similarity_aerial + w_streetview * similarity_streetview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2SZTmlRlmRs"
      },
      "outputs": [],
      "source": [
        "similarity_urban.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUFoP9xzokNP"
      },
      "source": [
        "Not strictly necessary, but you can visualize the cosine similarity scores for all examined cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvxnlPKR4_2m"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "titles = [\"Similarity: Aerial\", \"Similarity: Street\", \"Similarity: Urban\"]\n",
        "cmaps = ['Blues', 'Reds', 'Greens']\n",
        "datas = [similarity_aerial, similarity_streetview, similarity_urban]\n",
        "\n",
        "\n",
        "for ax, title, cmap, d in zip(axs, titles, cmaps, datas):\n",
        "    im = ax.imshow(d, cmap=cmap, vmin=0, vmax=1)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Building Index\")\n",
        "    ax.set_ylabel(\"Building Index\")\n",
        "\n",
        "    # Attach a colorbar of matching height\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    plt.colorbar(im, cax=cax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR638V8-ovni"
      },
      "source": [
        "You will now select one building (out of the 50) and will explore similar buildings based on the computed similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXMGx1tpYpF5"
      },
      "outputs": [],
      "source": [
        "# Similarity with respect to one building (index = 0)\n",
        "similarity_query_aerial = similarity_aerial[0].tolist() # Note torch tensors are converted to lists here\n",
        "similarity_query_streetview = similarity_streetview[0].tolist()\n",
        "similarity_query_urban = similarity_urban[0].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uXNmQZtpCyM"
      },
      "source": [
        "## üó∫ Visualizing building similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiJSs-5tpG8K"
      },
      "source": [
        "You have now computed the similarity score between a selected (query) building and a gallery of 50 buildings. Wouldn't it be great to visualize the results on a map? Let's do it. Are you more comfortable coding Python or interacting with QGIS interface? Either way will work!\n",
        "\n",
        "To visualize building similarity on a map, you will attach the computed similarity scores as additional columns to the original geopandas tile. Yes, the cycle is closing and we are moving back to the tile.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tZWax_cdpUbS"
      },
      "outputs": [],
      "source": [
        "id_to_index = {key: i for i, key in enumerate(street_view_coord.keys())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8kJ7NB3AEpv"
      },
      "outputs": [],
      "source": [
        "id_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ8RoxLNZZea"
      },
      "outputs": [],
      "source": [
        "# First, we add (sort of empty) columns to the tile. One for each case.\n",
        "subset_buildings = subset_buildings.copy()\n",
        "subset_buildings['aerial_similarity'] = np.nan\n",
        "subset_buildings['streetview_similarity'] = np.nan\n",
        "subset_buildings['urban_similarity'] = np.nan\n",
        "\n",
        "# Create a mapping from pand_id to index for faster lookup\n",
        "id_to_index = {key: i for i, key in enumerate(street_view_coord.keys())}\n",
        "\n",
        "# Then, we iterate over all 50 building footprints and include the corresponding similarity.\n",
        "for idx, row in subset_buildings.iterrows():\n",
        "\n",
        "    # Let's only collect the ID\n",
        "    pand_id = row[\"identificatie\"][14:]\n",
        "\n",
        "    if pand_id in id_to_index:\n",
        "        i = id_to_index[pand_id]\n",
        "\n",
        "        subset_buildings.loc[idx, 'aerial_similarity'] = similarity_query_aerial[i]\n",
        "        subset_buildings.loc[idx, 'streetview_similarity'] = similarity_query_streetview[i]\n",
        "        subset_buildings.loc[idx, 'urban_similarity'] = similarity_query_urban[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8w6iCYzq_Na"
      },
      "source": [
        "Let's now store our modified geopandas file, which contains now building similarity information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_KOhbYscOTo"
      },
      "outputs": [],
      "source": [
        "# Store GeoPandas\n",
        "subset_buildings.to_file(\"urban_similarity.gpkg\", driver='GPKG')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9SgAlbOrY21"
      },
      "source": [
        "### Visualization directly on Python\n",
        "\n",
        "You can now visualize, set up, and store plots directly on Python. Alternatively, this task can be done via QGIS' interface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKjTZOqErx1l"
      },
      "source": [
        "Let's plot, for instance, urban similarity. Note that you can refine the code to produce a figure that satisfy your needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Npa4rWPoZ-xl"
      },
      "outputs": [],
      "source": [
        "subset_buildings.plot(column='urban_similarity', legend=True, alpha=0.8, cmap='RdYlBu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGOfmfs8sDF_"
      },
      "source": [
        "Another example below. Here building similarity is visualized based on similarity scores computed from aerial, street view images, and a combination thereof."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBjdnUekbcXv"
      },
      "outputs": [],
      "source": [
        "# Create a figure and 3 subplots, organized horizontally (1 row, 3 columns)\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plotting the same 'column' with different color maps on each subplot\n",
        "subset_buildings.plot(column='aerial_similarity', ax=axs[0], legend=True, alpha=0.8, cmap='coolwarm_r', vmin=0, vmax=1)\n",
        "subset_buildings.plot(column='streetview_similarity', ax=axs[1], legend=True, alpha=0.8, cmap='coolwarm_r', vmin=0, vmax=1)\n",
        "subset_buildings.plot(column='urban_similarity', ax=axs[2], legend=True, alpha=0.8, cmap='coolwarm_r', vmin=0, vmax=1)\n",
        "\n",
        "# Set titles for each subplot for clarity\n",
        "axs[0].set_title('Aerial similarity')\n",
        "axs[1].set_title('Street view similarity')\n",
        "axs[2].set_title('Urban similarity')\n",
        "\n",
        "# Remove axis labels and tick labels for all subplots\n",
        "for ax in axs:\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_ylabel('')\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "\n",
        "# Adjust layout to make room for the legend\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDY1h9f0sUmi"
      },
      "source": [
        "(Optional) You can also visualize the images corresponding to certain building by following the code below. I know you are curious enough and would like to verify the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvdbaQvewr9u"
      },
      "outputs": [],
      "source": [
        "query_index = \"0503100000000172\"\n",
        "building_index = \"0503100000038135\"\n",
        "\n",
        "# Create the matplotlib grid for visualization\n",
        "fig, axs = plt.subplots(2, 2, figsize=(2 * 4, 1 * 4))\n",
        "\n",
        "aerial_image_ = \"aerial_images/\"+ query_index +\".jpg\"\n",
        "image_sim = np.array(Image.open(aerial_image_))\n",
        "axs[0, 0].imshow(image_sim)\n",
        "axs[0, 0].set_title(\"query: aerial\")  # Optional: Show filename as title\n",
        "axs[0, 0].axis('off')  # Hide axes for better visualization\n",
        "\n",
        "aerial_image_ = \"aerial_images/\" + building_index +\".jpg\"\n",
        "image_dis = np.array(Image.open(aerial_image_))\n",
        "axs[0, 1].imshow(image_dis)\n",
        "axs[0, 1].set_title(\"building: aerial\")  # Optional: Show filename as title\n",
        "axs[0, 1].axis('off')  # Hide axes for better visualization\n",
        "\n",
        "streetview_image_ = \"street_view_images/\"+ query_index +\".jpg\"\n",
        "image_sim = np.array(Image.open(streetview_image_))\n",
        "axs[1, 0].imshow(image_sim)\n",
        "axs[1, 0].set_title(\"query: street\")  # Optional: Show filename as title\n",
        "axs[1, 0].axis('off')  # Hide axes for better visualization\n",
        "\n",
        "streetview_image_ = \"street_view_images/\"+ building_index +\".jpg\"\n",
        "image_dis = np.array(Image.open(streetview_image_))\n",
        "axs[1, 1].imshow(image_dis)\n",
        "axs[1, 1].set_title(\"building: street\")  # Optional: Show filename as title\n",
        "axs[1, 1].axis('off')  # Hide axes for better visualization\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTDgdy5BRpbL"
      },
      "source": [
        "(Optional) And finally, let's set up our **building search engine**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qtDUPSoR9z7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def building_search(building_id, id_to_index, similarity_urban, subset_buildings, number_similar_buildings=3):\n",
        "    \"\"\"\n",
        "    - building_id: the query building ID (string).\n",
        "    - id_to_index: dict mapping building IDs to indices (for accessing similarity_urban).\n",
        "    - similarity_urban: a tensor/array of similarity scores, where similarity_urban[idx_list]\n",
        "      gives similarity scores to all other buildings from the query building index.\n",
        "    - subset_buildings: GeoDataFrame containing building footprints (with column 'identificatie').\n",
        "    - number_similar_buildings: how many similar buildings to retrieve and plot.\n",
        "\n",
        "    This function returns the IDs of the query building + similar buildings and\n",
        "    also shows:\n",
        "      1) a plot comparing their aerial and street view images, and\n",
        "      2) a plot of building footprints colored by similarity to the query building.\n",
        "    \"\"\"\n",
        "    # -- 1) Identify top-k similar buildings --\n",
        "    idx_list = id_to_index[building_id]  # retrieve index based on query building's ID\n",
        "\n",
        "    # similarity vector with respect to the query building\n",
        "    similarity_urban_ = similarity_urban[idx_list]\n",
        "\n",
        "    # topk returns (values, indices); we get the top-k + the query building itself\n",
        "    similarity_ranking, idx_ranking = similarity_urban_.topk(number_similar_buildings + 1)\n",
        "\n",
        "    # match these indices back to building IDs\n",
        "    all_building_ids = list(id_to_index.keys())\n",
        "    building_ids_ranking = [all_building_ids[i] for i in idx_ranking.tolist()]\n",
        "\n",
        "    # Building IDs: first one is the query building, subsequent ones are similar buildings\n",
        "    print(\"Query building: \", building_ids_ranking[0])\n",
        "    print(\"Similar buildings: \", building_ids_ranking[1:])\n",
        "\n",
        "    # -- 2) Plot the query and top-k similar buildings --\n",
        "    # We'll make a figure with 2 rows and (k + 1) columns\n",
        "    fig, axs = plt.subplots(\n",
        "        2,                       # two rows (row 0 = aerial, row 1 = street view)\n",
        "        number_similar_buildings + 1,  # columns = query + similar\n",
        "        figsize=((number_similar_buildings + 1) * 4, 2 * 4)  # adjust figure size\n",
        "    )\n",
        "\n",
        "    for col, b_id in enumerate(building_ids_ranking):\n",
        "        # Aerial image\n",
        "        aerial_path = f\"aerial_images/{b_id}.jpg\"\n",
        "        try:\n",
        "            aerial_img = np.array(Image.open(aerial_path))\n",
        "            axs[0, col].imshow(aerial_img)\n",
        "        except FileNotFoundError:\n",
        "            axs[0, col].text(0.5, 0.5, 'No aerial image found', ha='center', va='center')\n",
        "\n",
        "        axs[0, col].axis('off')\n",
        "        if col == 0:\n",
        "            axs[0, col].set_title(f\"Query aerial: {b_id}\")\n",
        "        else:\n",
        "            axs[0, col].set_title(f\"Sim. {col} aerial: {b_id}\")\n",
        "\n",
        "        # Street view\n",
        "        street_path = f\"street_view_images/{b_id}.jpg\"\n",
        "        try:\n",
        "            street_img = np.array(Image.open(street_path))\n",
        "            axs[1, col].imshow(street_img)\n",
        "        except FileNotFoundError:\n",
        "            axs[1, col].text(0.5, 0.5, 'No street image found', ha='center', va='center')\n",
        "\n",
        "        axs[1, col].axis('off')\n",
        "        if col == 0:\n",
        "            axs[1, col].set_title(f\"Query street: {b_id}\")\n",
        "        else:\n",
        "            axs[1, col].set_title(f\"Sim. {col} street: {b_id}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # -- 3) Add similarity columns to a copy of your building footprints GeoDataFrame --\n",
        "    subset_build = subset_buildings.copy()\n",
        "    subset_build['aerial_similarity'] = np.nan\n",
        "    subset_build['streetview_similarity'] = np.nan\n",
        "    subset_build['urban_similarity'] = np.nan\n",
        "\n",
        "    # For each row in the GeoDataFrame, fill in the similarity value for that building\n",
        "    for idx, row in subset_build.iterrows():\n",
        "        # Extract building ID (e.g., skipping first 14 chars if that's correct for your data)\n",
        "        pand_id = row[\"identificatie\"][14:]\n",
        "\n",
        "        if pand_id in id_to_index:\n",
        "            i = id_to_index[pand_id]\n",
        "            # similarity_urban_ is the entire similarity vector for the query building vs. all others\n",
        "            # so the similarity for building i is:\n",
        "            subset_build.loc[idx, 'urban_similarity'] = similarity_urban_[i].tolist()\n",
        "            # If you had separate arrays for aerial/street similarity, you‚Äôd do:\n",
        "            # subset_build.loc[idx, 'aerial_similarity'] = similarity_aerial_[i]\n",
        "            # subset_build.loc[idx, 'streetview_similarity'] = similarity_street_[i]\n",
        "\n",
        "    # -- 4) Plot the GeoDataFrame colored by similarity (e.g., 'urban_similarity') --\n",
        "    # Example: 1 row, 1 subplot for just 'urban_similarity'.\n",
        "    # If you also want to show 'aerial_similarity' and 'streetview_similarity',\n",
        "    # you can make multiple subplots. Below is a single-subplot example.\n",
        "\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # -- 4) Plot the GeoDataFrame colored by 'urban_similarity'\n",
        "    #      and highlight the query + 3 similar buildings\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    # 1) Separate out query vs. similar IDs\n",
        "    query_id = building_ids_ranking[0]      # first is the query\n",
        "    similar_ids = building_ids_ranking[1:]  # the next 'number_similar_buildings' are similar\n",
        "\n",
        "    # 2) Make small GeoDataFrames for the query and similar sets\n",
        "    query_building = subset_build[ subset_build[\"identificatie\"].str[14:] == query_id ]\n",
        "    similar_buildings = subset_build[ subset_build[\"identificatie\"].str[14:].isin(similar_ids) ]\n",
        "\n",
        "    # Base map (polygons colored by similarity)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(15, 6))\n",
        "    subset_build.plot(\n",
        "        column='urban_similarity',\n",
        "        ax=ax,\n",
        "        legend=True,           # colorbar for the similarity column\n",
        "        alpha=0.8,\n",
        "        cmap='coolwarm_r',\n",
        "        vmin=0,\n",
        "        vmax=1,\n",
        "        label='_nolegend_'     # don't put these polygons in the legend\n",
        "    )\n",
        "\n",
        "    # We only want a \"dot\" marker for query/similar buildings.\n",
        "    # Polygons can't be displayed with a marker symbol, so we convert them to point centroids:\n",
        "    query_centroid = query_building.copy()\n",
        "    query_centroid[\"geometry\"] = query_centroid.geometry.centroid\n",
        "\n",
        "    similar_centroids = similar_buildings.copy()\n",
        "    similar_centroids[\"geometry\"] = similar_centroids.geometry.centroid\n",
        "\n",
        "    # Plot the query centroid as a red 'X'\n",
        "    query_centroid.plot(\n",
        "        ax=ax,\n",
        "        marker='X',\n",
        "        color='red',\n",
        "        markersize=4,\n",
        "        label='Query Building'\n",
        "    )\n",
        "\n",
        "    # Plot the similar buildings as black circles\n",
        "    similar_centroids.plot(\n",
        "        ax=ax,\n",
        "        marker='o',\n",
        "        color='black',\n",
        "        markersize=4,\n",
        "        label='Similar Buildings'\n",
        "    )\n",
        "\n",
        "    # Final formatting\n",
        "    ax.set_title('Urban similarity')\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_ylabel('')\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "\n",
        "    # This automatically handles the two point layers (query & similar) in the legend\n",
        "    ax.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABxi5iFISDkc"
      },
      "outputs": [],
      "source": [
        "# 0503100000037163 (standard building)\n",
        "# 0503100000000172 (large building)\n",
        "\n",
        "building_search(\"0503100000037163\", id_to_index, similarity_urban, subset_buildings, number_similar_buildings=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGT0Tct-6iE8"
      },
      "source": [
        "## üßô Additional hints and tricks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeD7rAyM6zmA"
      },
      "source": [
        "**Merging geopandas files**\n",
        "Say you would like to combine two (or more) tiles of building footprints (maybe) retrieved from 3D BAG. You just have to concatanate the individual geopandas as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8cPPdNp6zmA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load another tile\n",
        "path_to_data = \"second_tile.gpkg\"\n",
        "second_tile = geopandas.read_file(path_to_data)\n",
        "# Concatenate geopandas\n",
        "tile_concat = pd.concat([tile, second_tile], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7Ajf7XZ9Vrc"
      },
      "outputs": [],
      "source": [
        "# Plot buildings footprint\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 10))\n",
        "tile_concat.plot(column='b3_dak_type', legend=False, alpha=0.8) # Footprint roof type\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qtSFjmS6zmA"
      },
      "source": [
        "**Transform geographical coordinates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFz_Uwx66zmB"
      },
      "outputs": [],
      "source": [
        "from pyproj import Transformer\n",
        "\n",
        "# Create a transformer object for converting from EPSG:4326 to EPSG:28992\n",
        "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:28992\", always_xy=True)\n",
        "\n",
        "# Example coordinates from Google Maps (longitude, latitude)\n",
        "google_maps_coordinate = (4.475639, 51.922667)  # Longitude, Latitude\n",
        "\n",
        "# Transform the coordinate\n",
        "rd_new_coordinate = transformer.transform(*google_maps_coordinate)\n",
        "\n",
        "print(f\"RD New Coordinate: {rd_new_coordinate}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeh4HuQ-6zmB"
      },
      "source": [
        "**(Bonus info)**\n",
        "You can find the geographical coordinates related to all buildings investigated in the group projects.\n",
        "\n",
        "- Lumiere: 51¬∞55'21.6\"N 4¬∞28'32.3\"E. // 51.922667, 4.475639.\n",
        "- Strijp-S: 51¬∞26'48.8\"N 5¬∞27'31.9\"E. // 51.446889, 5.458861.\n",
        "- The Stack: 52¬∞23'14.7\"N 4¬∞54'13.4\"E. // 52.387417, 4.903722.\n",
        "- SPOT: 52¬∞18'25.6\"N 4¬∞56'45.1\"E. // 52.307111, 4.945861."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHY-OgXgNIF2"
      },
      "source": [
        "### Visualization via QGIS interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af0uLMJeL4-r"
      },
      "source": [
        "**Import GeoPandas file**\n",
        "\n",
        "To import a GeoPandas package, go to the data source manager and upload the file as indicated in the illustration below.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1YHWE6roq3vuKu0V6gFnhJKvZqv5sa2JE\" alt=\"floor-layout\" class=\"center\" width=\"500px\">\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN32-RMdMT82"
      },
      "source": [
        "**Set up visualization settings**\n",
        "\n",
        "GeoPandas loaded, yeah! You can now color-code building footprints according to the computed similarity scores by changing the properties of the layer. Specifically, you can color-code items categorically or gradually. The latter can be very useful to visualize similarity measures. But, of course, you are free to decide the final setup.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Xeh6hTlppwydBgIGDY819TEJSZjwZD0O\" alt=\"floor-layout\" class=\"center\" width=\"500px\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVe7TyseMjKO"
      },
      "source": [
        "**Export canvas (map)**\n",
        "\n",
        "Once you have finalized adjusting the colormap (surely you will take some time to make up your mind), you can then export the map as indicated below. There are two options:\n",
        "- Fast export: you can quickly export the map as a pdf/image.\n",
        "- Detailed export: additional settings can be carefully selected if you create a new print layout.\n",
        "\n",
        "You can find more info [here](https://docs.qgis.org/3.34/en/docs/training_manual/map_composer/map_composer.html).\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1CGSxUEUTfdHf3Vg2dBmKV2yIHwG9-39v\" alt=\"floor-layout\" class=\"center\" width=\"500px\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOc3cnfoNanD"
      },
      "source": [
        "# ‚úÖ Assignment: Represent your own urban similarity map!\n",
        "\n",
        "- 1p: retrieve street view images for each building footprint contained in the tile corresponding to your project. Retrieve images for the same buildings assigned to you in Tutorial 4.\n",
        "- 1p: compute the embedding representations of the collected street view images through DINOv2, store them, and share your local directory (see more instructions below).\n",
        "- 2p: extract the footprint for a **query building** different from the buildings in your gallery. It could be your project's building or other building of your choice. Tip: you may postprocess your query aerial and/or street view images so that they resemble most of the to-be-built building if the project has not been completed yet.\n",
        "- 1p: collect the aerial and street-view images corresponding to your query building\n",
        "- 1p: compute the embedding for your query building via DINOv2\n",
        "- 2p: calculate the urban similarity between your query building and all buildings contained in your local gallery\n",
        "- 2p: visualize the computed urban similarity on a map, color-coding buildings according to their similarity score to your *query* building.\n",
        "\n",
        "### **Output**</br>\n",
        "**Write your findings and interpretation in a notebook** named **\"A7_urban_similarity_\\<name\\>.ipynb\"**.\n",
        "\n",
        "**Share the folder** containing the collected building street-view images.\n",
        "\n",
        "! Please include the links pointing to the notebook and local folder when submitting the assignment on Brightspace.\n",
        "\n",
        "- Deadline: Friday, April 11\n",
        "\n",
        "‚è∞ Street-view images must by shared by **Monday, April 7**. You can share the link (per person or group) to `p.g.moratodominguez@tudelft.nl`.\n",
        "\n",
        "**(Important)** The images must be named according to the building's PAND ID. Example: `0503100000037135.jpg`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7oBH0203Fee"
      },
      "source": [
        "## Additional guidelines\n",
        "\n",
        "#### Neighborhood\n",
        "You will collect building images from a specific neeighborhood within the `Hof van Delft` district, in Delft. Each group will deal with a specific neighborhood:\n",
        "\n",
        "- Group 1: `Bedrijventerrein Altena`\n",
        "- Group 2: `Agnetaparkbuurt`\n",
        "- Group 3: `Ministersbuurt-West`\n",
        "- Group 4: `Ministersbuurt-Oost`\n",
        "- Group 5: `Westeindebuurt`\n",
        "- Group 6: `Olofsbuurt`\n",
        "- Group 7: `Krakeelpolder`\n",
        "- Group 8: `Westerkwartier`\n",
        "\n",
        "#### Subset\n",
        "Coordinate with your group to decide the subset of buildings you will individually focus on.\n",
        "\n",
        "#### Data storage\n",
        "Place the street view images and dictionary into a local folder.\n",
        "\n",
        "üëâ You can download building and neighborhood data for the `Hof van Delft` district [here](https://drive.google.com/drive/folders/1r6RPCXV_DLK2EdQHnqhCL2oimnBZL_hM?usp=sharing)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
